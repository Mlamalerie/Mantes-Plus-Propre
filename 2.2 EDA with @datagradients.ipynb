{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "Whether you're working on image classification, object detection, or semantic segmentation, DataGradients helps you gain insights and analyze your datasets effectively.\n",
    "\n",
    "In this tutorial, you'll explore the features and functionalities of DataGradients, guiding you through comprehensive data analysis for computer vision projects.\n",
    "\n",
    "With DataGradients, you can:\n",
    "\n",
    "- Analyze image features such as color distribution, brightness, and size.\n",
    "- Profile object detection datasets with metrics like bounding box area, intersection, and class frequency.\n",
    "- Understand segmentation datasets using object area, width, height, and class frequency.\n",
    "- Visualize samples for a better understanding. And much more\n",
    "\n",
    "- Profiling your datasets has never been easier!\n",
    "\n",
    "In this notebook, you must have a **dataset in the YOLO format**."
   ],
   "metadata": {
    "id": "RLWS0m9zPSoN"
   },
   "id": "RLWS0m9zPSoN"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports - librairies\n"
   ],
   "metadata": {
    "id": "SF7dbEk6F2Nw"
   },
   "id": "SF7dbEk6F2Nw"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install data-gradients\n",
    "\n",
    "# for displaying pdfs as images in notebook\n",
    "!pip install pdf2image\n",
    "!apt-get -y install poppler-utils\n",
    "\n",
    "# for pretty printing json\n",
    "!pip install Pygments"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d_PZw18Bg46",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869985344,
     "user_tz": -60,
     "elapsed": 36549,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "cfdd38ef-7bd6-468c-bd4f-390075f75589"
   },
   "id": "9d_PZw18Bg46",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: data-gradients in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
      "Requirement already satisfied: hydra-core>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.3.2)\n",
      "Requirement already satisfied: omegaconf>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.3.0)\n",
      "Requirement already satisfied: pygments>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.16.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.66.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.1.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from data-gradients) (9.4.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.15.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.16.0+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.7.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.11.4)\n",
      "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.5.2)\n",
      "Requirement already satisfied: coverage~=5.3.1 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (5.3.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.12.2)\n",
      "Requirement already satisfied: xhtml2pdf==0.2.11 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.2.11)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.1.2)\n",
      "Requirement already satisfied: imagededup in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.3.2)\n",
      "Requirement already satisfied: arabic-reshaper>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.0.0)\n",
      "Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (1.1)\n",
      "Requirement already satisfied: pyHanko>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.21.0)\n",
      "Requirement already satisfied: pyhanko-certvalidator>=0.19.5 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.26.3)\n",
      "Requirement already satisfied: pypdf>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.17.3)\n",
      "Requirement already satisfied: python-bidi>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.4.2)\n",
      "Requirement already satisfied: reportlab<4,>=3.5.53 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.6.13)\n",
      "Requirement already satisfied: svglib>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (1.5.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.2.0->data-gradients) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.2.0->data-gradients) (23.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.2.3->data-gradients) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients) (1.2.2)\n",
      "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->data-gradients) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients) (1.5.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (2.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->data-gradients) (1.3.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf==0.2.11->data-gradients) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->data-gradients) (2023.3.post1)\n",
      "Requirement already satisfied: asn1crypto>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (1.5.1)\n",
      "Requirement already satisfied: qrcode>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (7.4.2)\n",
      "Requirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (5.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (8.1.7)\n",
      "Requirement already satisfied: cryptography>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (41.0.7)\n",
      "Requirement already satisfied: oscrypto>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients) (1.3.0)\n",
      "Requirement already satisfied: uritools>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (2023.11.17)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (4.9.3)\n",
      "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (1.2.1)\n",
      "Requirement already satisfied: cssselect2>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->data-gradients) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->data-gradients) (0.5.1)\n",
      "Requirement already satisfied: pypng in /usr/local/lib/python3.10/dist-packages (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (0.20220715.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->data-gradients) (3.2.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (2.21)\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "poppler-utils is already the newest version (22.02.0-2ubuntu0.3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
      "Requirement already satisfied: Pygments in /usr/local/lib/python3.10/dist-packages (2.16.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import seaborn as sns  # library for visualization\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt  # library for visualization\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "import warnings\n",
    "import re"
   ],
   "metadata": {
    "id": "f-Cq6o7eRsJ5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869985345,
     "user_tz": -60,
     "elapsed": 162,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    }
   },
   "id": "f-Cq6o7eRsJ5",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up Google Drive"
   ],
   "metadata": {
    "id": "hONZlfgnFzFm"
   },
   "id": "hONZlfgnFzFm"
  },
  {
   "cell_type": "code",
   "source": [
    "SET_UP_GOOGLE_DRIVE = True\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "id": "NFg0KY0rFqKw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869987179,
     "user_tz": -60,
     "elapsed": 1994,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "bfacf8a2-7d41-41fc-90e5-cfdee5b19acd"
   },
   "id": "NFg0KY0rFqKw",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🛠️ Utility functions"
   ],
   "metadata": {
    "id": "KGHHD-Q_QA3o"
   },
   "id": "KGHHD-Q_QA3o"
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "\n",
    "def display_pdf_pages(pdf_path):\n",
    "    \"\"\"\n",
    "    Display each page of a PDF file as images in separate output cells.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified PDF file is not found.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PDF to a list of PIL Images\n",
    "        images = convert_from_path(pdf_path)\n",
    "\n",
    "        # Display each image\n",
    "        for i, image in enumerate(images):\n",
    "            # Display the image\n",
    "            display(image)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"The specified PDF file was not found.\")"
   ],
   "metadata": {
    "id": "tQd3Oy_cP9Or",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869987180,
     "user_tz": -60,
     "elapsed": 53,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    }
   },
   "id": "tQd3Oy_cP9Or",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 : Prepare Dataset"
   ],
   "metadata": {
    "id": "brREhjdRPq4j"
   },
   "id": "brREhjdRPq4j"
  },
  {
   "cell_type": "code",
   "source": [
    "if SET_UP_GOOGLE_DRIVE:\n",
    "    DATASETS_DIR_ROOT_PATH = r\"/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets\"\n",
    "    EDA_DATAGRADIENT_OUTPUTS_PATH =  r\"/content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients\"\n",
    "else:\n",
    "    EDA_DATAGRADIENT_OUTPUTS_PATH = \"/outputs/eda-datagradients\"\n",
    "print(DATASETS_DIR_ROOT_PATH)\n",
    "print(os.listdir(DATASETS_DIR_ROOT_PATH))\n",
    "MY_DATASET_PATH = os.path.join(DATASETS_DIR_ROOT_PATH,'taco-2gb-updated-2023121718')\n",
    "if not os.path.exists(MY_DATASET_PATH):\n",
    "    raise FileExistsError(\"ehhh\")\n",
    "MY_DATASET_PATH"
   ],
   "metadata": {
    "id": "hTKkatu6F9_6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869987182,
     "user_tz": -60,
     "elapsed": 52,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "7008be47-51df-4bd2-e77f-33314b367f88"
   },
   "id": "hTKkatu6F9_6",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets\n",
      "['taco-2gb', 'taco-2gb-updated', 'taco-2gb-updated-2023121620', 'taco-2gb-updated-2023121621', 'taco-2gb-updated-2023121718']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets/taco-2gb-updated-2023121718'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "# define the path to your YAML file\n",
    "yaml_file_path = os.path.join(MY_DATASET_PATH, \"data.yaml\")\n",
    "\n",
    "# open the YAML file and load it into a dictionary\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "data_yaml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RotS4DoSQTm6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869987597,
     "user_tz": -60,
     "elapsed": 455,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "716daec2-424a-4d87-aa5d-d38f463c58c0"
   },
   "id": "RotS4DoSQTm6",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': '../train/images',\n",
       " 'val': '../val/images',\n",
       " 'nc': 59,\n",
       " 'names': {0: 'Aluminium foil',\n",
       "  1: 'Battery',\n",
       "  2: 'Aluminium blister pack',\n",
       "  3: 'Carded blister pack',\n",
       "  4: 'Other plastic bottle',\n",
       "  5: 'Clear plastic bottle',\n",
       "  6: 'Glass bottle',\n",
       "  7: 'Plastic bottle cap',\n",
       "  8: 'Metal bottle cap',\n",
       "  9: 'Broken glass',\n",
       "  10: 'Food Can',\n",
       "  11: 'Aerosol',\n",
       "  12: 'Drink can',\n",
       "  13: 'Toilet tube',\n",
       "  14: 'Other carton',\n",
       "  15: 'Egg carton',\n",
       "  16: 'Drink carton',\n",
       "  17: 'Corrugated carton',\n",
       "  18: 'Meal carton',\n",
       "  19: 'Pizza box',\n",
       "  20: 'Paper cup',\n",
       "  21: 'Disposable plastic cup',\n",
       "  22: 'Foam cup',\n",
       "  23: 'Glass cup',\n",
       "  24: 'Other plastic cup',\n",
       "  25: 'Food waste',\n",
       "  26: 'Glass jar',\n",
       "  27: 'Plastic lid',\n",
       "  28: 'Metal lid',\n",
       "  29: 'Other plastic',\n",
       "  30: 'Magazine paper',\n",
       "  31: 'Tissues',\n",
       "  32: 'Wrapping paper',\n",
       "  33: 'Normal paper',\n",
       "  34: 'Paper bag',\n",
       "  35: 'Plastic film',\n",
       "  36: 'Six pack rings',\n",
       "  37: 'Garbage bag',\n",
       "  38: 'Other plastic wrapper',\n",
       "  39: 'Single-use carrier bag',\n",
       "  40: 'Polypropylene bag',\n",
       "  41: 'Crisp packet',\n",
       "  42: 'Spread tub',\n",
       "  43: 'Tupperware',\n",
       "  44: 'Disposable food container',\n",
       "  45: 'Foam food container',\n",
       "  46: 'Other plastic container',\n",
       "  47: 'Plastic glooves',\n",
       "  48: 'Plastic utensils',\n",
       "  49: 'Pop tab',\n",
       "  50: 'Rope & strings',\n",
       "  51: 'Scrap metal',\n",
       "  52: 'Shoe',\n",
       "  53: 'Squeezable tube',\n",
       "  54: 'Plastic straw',\n",
       "  55: 'Paper straw',\n",
       "  56: 'Styrofoam piece',\n",
       "  57: 'Unlabeled litter',\n",
       "  58: 'Cigarette'}}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 💾 Step 2: Instantiating Dataloaders"
   ],
   "metadata": {
    "id": "YxlzKjvoQgTB"
   },
   "id": "YxlzKjvoQgTB"
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_params = {\n",
    "    'data_dir':MY_DATASET_PATH,\n",
    "    'train_images_dir':'train/images',\n",
    "    'train_labels_dir':'train/labels',\n",
    "    'val_images_dir':'val/images',\n",
    "    'val_labels_dir':'val/labels',\n",
    "    'test_images_dir':'test/images',\n",
    "    'test_labels_dir':'test/labels',\n",
    "    'classes': data_yaml['names']\n",
    "}"
   ],
   "metadata": {
    "id": "qDjd1jgEQ5_r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702869987598,
     "user_tz": -60,
     "elapsed": 18,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    }
   },
   "id": "qDjd1jgEQ5_r",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from data_gradients.datasets.detection import YoloFormatDetectionDataset\n",
    "\n",
    "train_set = YoloFormatDetectionDataset(root_dir=dataset_params['data_dir'],\n",
    "                                       images_dir=dataset_params['train_images_dir'],\n",
    "                                       labels_dir=dataset_params['train_labels_dir'])\n",
    "\n",
    "val_set = YoloFormatDetectionDataset(root_dir=dataset_params['data_dir'],\n",
    "                                     images_dir=dataset_params['val_images_dir'],\n",
    "                                     labels_dir=dataset_params['val_labels_dir'])\n",
    "\n"
   ],
   "metadata": {
    "id": "raWqR1_MCr2N",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702870001210,
     "user_tz": -60,
     "elapsed": 13629,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    }
   },
   "id": "raWqR1_MCr2N",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_set), len(val_set)"
   ],
   "metadata": {
    "id": "-jGeIES4EODP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702870001212,
     "user_tz": -60,
     "elapsed": 25,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "1cce21c6-4b6f-43d8-a2fc-845087896b19",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "-jGeIES4EODP",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1394, 480)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📊 Step 3: Perform Analysis"
   ],
   "metadata": {
    "id": "Il4CbOnnRKPZ"
   },
   "id": "Il4CbOnnRKPZ"
  },
  {
   "cell_type": "code",
   "source": [
    "from data_gradients.managers.detection_manager import DetectionAnalysisManager\n",
    "from data_gradients.feature_extractors.common import ImageDuplicates\n",
    "from data_gradients.feature_extractors.common.sample_visualization import AbstractSampleVisualization\n",
    "from data_gradients.utils.data_classes.image_channels import ImageChannels\n",
    "import matplotlib\n",
    "\n",
    "ImageDuplicates(train_image_dir=dataset_params['train_images_dir'],valid_image_dir=dataset_params['val_images_dir'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rm6psd9kWcLb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702870053108,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "ebf0f560-32e5-46e5-9351-67ff08302599"
   },
   "id": "Rm6psd9kWcLb",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ImageDuplicates"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "f\"{MY_DATASET_PATH}/train/images\",f\"{MY_DATASET_PATH}/val/images\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIRTP-co9aPN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702870067140,
     "user_tz": -60,
     "elapsed": 217,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "6336d161-7d92-4c5c-d740-8e1342a035bf"
   },
   "id": "MIRTP-co9aPN",
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets/taco-2gb-updated-2023121718/train/images',\n",
       " '/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets/taco-2gb-updated-2023121718/val/images')"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "REPORT_TITLE = \"TACO - Exploratory Data Analysis (Object Detection)\"\n",
    "REPORT_SUBTITLE = f\"dataset_path: {MY_DATASET_PATH}\"\n",
    "now_str = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "LOG_DIR = f\"{EDA_DATAGRADIENT_OUTPUTS_PATH}/{REPORT_TITLE} {now_str}\"\n",
    "LOG_DIR"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "blttfC8qt9qR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702870074720,
     "user_tz": -60,
     "elapsed": 217,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "3d959f15-34ed-4c88-fc1b-6dd1db191e51"
   },
   "id": "blttfC8qt9qR",
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients/TACO - Exploratory Data Analysis (Object Detection) 20231218_03'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 36
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "matplotlib.use('Agg') # This line is only for Colab\n",
    "\n",
    "analyzer = DetectionAnalysisManager(\n",
    "    report_title=REPORT_TITLE,\n",
    "    report_subtitle=REPORT_SUBTITLE,\n",
    "    train_data=train_set,\n",
    "    val_data=val_set,\n",
    "    class_names=dataset_params['classes'],\n",
    "    log_dir = LOG_DIR ,\n",
    "    is_label_first=True,\n",
    "    image_channels=ImageChannels.from_str(\"RGB\"),\n",
    "    bbox_format=\"cxcywh\",\n",
    "    remove_plots_after_report=False,\n",
    "    config_path=f\"{EDA_DATAGRADIENT_OUTPUTS_PATH}/config.yaml\"\n",
    ")\n",
    "\n",
    "analyzer.run()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTyHdeFkRUhC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702872630149,
     "user_tz": -60,
     "elapsed": 2554007,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "eec19f7a-fee2-4ff4-ac90-4882b355987a"
   },
   "id": "xTyHdeFkRUhC",
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image duplicates extraction: please enter the full path to the directory containing all train images >>> \n",
      "/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets/taco-2gb-updated-2023121718/train/images\n",
      "Image duplicates extraction: please enter the full path to the directory containing all validation images >>> \n",
      "/content/gdrive/MyDrive/KESKIA Drive Mlamali/datasets/taco-2gb-updated-2023121718/val/images\n",
      "  - Executing analysis with: \n",
      "  - batches_early_stop: None \n",
      "  - len(train_data): 1394 \n",
      "  - len(val_data): 480 \n",
      "  - log directory: /content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients/TACO - Exploratory Data Analysis (Object Detection) 20231218_03 \n",
      "  - Archive directory: /content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients/TACO - Exploratory Data Analysis (Object Detection) 20231218_03/archive_20231218-032757 \n",
      "  - feature extractor list: {'Image Features': [SummaryStats, ImagesResolution, ImageColorDistribution, ImagesAverageBrightness, ImageDuplicates], 'Object Detection Features': [DetectionSampleVisualization, DetectionClassHeatmap, DetectionBoundingBoxArea, DetectionBoundingBoxPerImageCount, DetectionBoundingBoxSize, DetectionClassFrequency, DetectionClassesPerImageCount, DetectionBoundingBoxIoU, DetectionResizeImpact]}\n",
      "\u001B[34;1m╔\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m╗\u001B[0m\n",
      "\u001B[34;1m║  \u001B[0mTo better understand how to tackle the data issues highlighted in this\u001B[34;1m  ║\u001B[0m\n",
      "\u001B[34;1m║  \u001B[0mreport, explore our comprehensive course on analyzing computer vision \u001B[34;1m  ║\u001B[0m\n",
      "\u001B[34;1m║  \u001B[0mdatasets. click here: https://hubs.ly/Q01XpHBT0                       \u001B[34;1m  ║\u001B[0m\n",
      "\u001B[34;1m╚\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m═\u001B[0m\u001B[34;1m╝\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Analyzing... : 100%|██████████| 1394/1394 [36:12<00:00,  1.56s/it]\n",
      "Summarizing... :   0%|          | 0/2 [00:00<?, ?it/s]Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "\n",
      "  0%|          | 0.00/9.83M [00:00<?, ?B/s]\u001B[A\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 68.7MB/s]\n",
      "2023-12-18 04:04:28,031: INFO Start: Calculating hashes...\n",
      "INFO:imagededup.methods.hashing:Start: Calculating hashes...\n",
      "\n",
      "  0%|          | 0/1394 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/1394 [00:44<17:23:48, 44.96s/it]\u001B[A\n",
      " 14%|█▍        | 201/1394 [01:07<05:21,  3.71it/s] \u001B[A\n",
      " 22%|██▏       | 301/1394 [01:11<03:09,  5.78it/s]\u001B[A\n",
      " 22%|██▏       | 301/1394 [01:25<03:09,  5.78it/s]\u001B[A\n",
      " 29%|██▉       | 401/1394 [01:40<03:35,  4.61it/s]\u001B[A\n",
      " 36%|███▌      | 501/1394 [01:43<02:15,  6.57it/s]\u001B[A\n",
      " 36%|███▌      | 501/1394 [01:55<02:15,  6.57it/s]\u001B[A\n",
      " 43%|████▎     | 601/1394 [02:11<02:33,  5.17it/s]\u001B[A\n",
      " 50%|█████     | 701/1394 [02:13<01:37,  7.14it/s]\u001B[A\n",
      " 50%|█████     | 701/1394 [02:25<01:37,  7.14it/s]\u001B[A\n",
      " 57%|█████▋    | 801/1394 [02:37<01:40,  5.90it/s]\u001B[A\n",
      " 65%|██████▍   | 901/1394 [02:41<01:03,  7.75it/s]\u001B[A\n",
      " 65%|██████▍   | 901/1394 [02:55<01:03,  7.75it/s]\u001B[A\n",
      " 72%|███████▏  | 1001/1394 [02:57<00:55,  7.10it/s]\u001B[A\n",
      " 79%|███████▉  | 1101/1394 [03:07<00:37,  7.91it/s]\u001B[A\n",
      " 79%|███████▉  | 1101/1394 [03:25<00:37,  7.91it/s]\u001B[A\n",
      " 86%|████████▌ | 1201/1394 [03:42<00:37,  5.15it/s]\u001B[A\n",
      "100%|██████████| 1394/1394 [03:45<00:00,  6.19it/s]\n",
      "2023-12-18 04:08:13,683: INFO End: Calculating hashes!\n",
      "INFO:imagededup.methods.hashing:End: Calculating hashes!\n",
      "2023-12-18 04:08:13,850: INFO Start: Calculating hashes...\n",
      "INFO:imagededup.methods.hashing:Start: Calculating hashes...\n",
      "\n",
      "  0%|          | 0/480 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/480 [00:32<4:16:36, 32.14s/it]\u001B[A\n",
      " 21%|██        | 101/480 [00:43<02:07,  2.98it/s]\u001B[A\n",
      " 42%|████▏     | 201/480 [01:01<01:08,  4.10it/s]\u001B[A\n",
      " 63%|██████▎   | 301/480 [01:12<00:32,  5.46it/s]\u001B[A\n",
      "100%|██████████| 480/480 [01:18<00:00,  6.08it/s]\n",
      "2023-12-18 04:09:33,016: INFO End: Calculating hashes!\n",
      "INFO:imagededup.methods.hashing:End: Calculating hashes!\n",
      "/usr/local/lib/python3.10/dist-packages/imagededup/methods/hashing.py:317: RuntimeWarning: Parameter num_enc_workers has no effect since encodings are already provided\n",
      "  warnings.warn('Parameter num_enc_workers has no effect since encodings are already provided', RuntimeWarning)\n",
      "2023-12-18 04:09:33,031: INFO Start: Evaluating hamming distances for getting duplicates\n",
      "INFO:imagededup.methods.hashing:Start: Evaluating hamming distances for getting duplicates\n",
      "2023-12-18 04:09:33,035: INFO Start: Retrieving duplicates using Cython Brute force algorithm\n",
      "INFO:imagededup.handlers.search.retrieval:Start: Retrieving duplicates using Cython Brute force algorithm\n",
      "\n",
      "  0%|          | 0/1874 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/1874 [00:00<06:45,  4.62it/s]\u001B[A\n",
      " 11%|█         | 201/1874 [00:00<00:03, 489.22it/s]\u001B[A\n",
      " 21%|██▏       | 401/1874 [00:00<00:02, 659.89it/s]\u001B[A\n",
      " 32%|███▏      | 601/1874 [00:00<00:01, 726.49it/s]\u001B[A\n",
      " 43%|████▎     | 801/1874 [00:01<00:01, 769.95it/s]\u001B[A\n",
      " 53%|█████▎    | 1001/1874 [00:01<00:01, 797.48it/s]\u001B[A\n",
      " 64%|██████▍   | 1201/1874 [00:01<00:00, 802.58it/s]\u001B[A\n",
      " 75%|███████▍  | 1401/1874 [00:01<00:00, 815.27it/s]\u001B[A\n",
      "100%|██████████| 1874/1874 [00:02<00:00, 839.30it/s]\n",
      "2023-12-18 04:09:35,463: INFO End: Retrieving duplicates using Cython Brute force algorithm\n",
      "INFO:imagededup.handlers.search.retrieval:End: Retrieving duplicates using Cython Brute force algorithm\n",
      "2023-12-18 04:09:35,467: INFO End: Evaluating hamming distances for getting duplicates\n",
      "INFO:imagededup.methods.hashing:End: Evaluating hamming distances for getting duplicates\n",
      "Summarizing... : 100%|██████████| 2/2 [05:48<00:00, 174.32s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset successfully analyzed!\n",
      "Starting to write the report, this may take around 10 seconds...\n",
      "\n",
      "====================================================================================================\n",
      "Your dataset evaluation has been completed!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training Configuration...\n",
      "`DetectionDataConfig` cache is not enabled because `cache_path=None` was not set.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Report Location:\n",
      "    - Temporary Folder (will be overwritten next run):\n",
      "        └─ /content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients/TACO - Exploratory Data Analysis (Object Detection) 20231218_03\n",
      "                ├─ Report.pdf\n",
      "                └─ summary.json\n",
      "    - Archive Folder:\n",
      "        └─ /content/gdrive/MyDrive/KESKIA Drive Mlamali/CDuPropreMantes/outputs/eda-datagradients/TACO - Exploratory Data Analysis (Object Detection) 20231218_03/archive_20231218-032757\n",
      "                ├─ Report.pdf\n",
      "                └─ summary.json\n",
      "\n",
      "====================================================================================================\n",
      "Seen a glitch? Have a suggestion? Visit https://github.com/Deci-AI/data-gradients !\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: View Full PDF Report\n"
   ],
   "metadata": {
    "id": "cnR5lAqERY1R"
   },
   "id": "cnR5lAqERY1R"
  },
  {
   "cell_type": "code",
   "source": [
    "# this function was defined and described at the beginning of this notebook\n",
    "display_pdf_pages(f\"{LOG_DIR}/Report.pdf\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1Mf2fvWGMrvfDkt2wpEjjjBA0iuSsbz8_"
    },
    "id": "Q-BH0gi8Ctw1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702865932457,
     "user_tz": -60,
     "elapsed": 7623,
     "user": {
      "displayName": "M SAID",
      "userId": "16677121514363856115"
     }
    },
    "outputId": "cc5878db-16af-4d69-a1d6-b73ea2540f20"
   },
   "id": "Q-BH0gi8Ctw1",
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output hidden; open in https://colab.research.google.com to view."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ⬇️ Download Report"
   ],
   "metadata": {
    "id": "6pDsbY3cR_RG"
   },
   "id": "6pDsbY3cR_RG"
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(f\"{LOG_DIR}/Report.pdf\")"
   ],
   "metadata": {
    "id": "VYcQm787T6Vq"
   },
   "id": "VYcQm787T6Vq",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
